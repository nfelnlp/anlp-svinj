Fachleute warnen vor Terminator-Armee			

Menschenrechtsorganisationen und Experten appellieren an Regierungen, Entwicklung und Einsatz waffenfähiger künstlicher Intelligenz zu kontrollieren oder ganz zu verbieten.
Fördern Sie ehrlichen Journalismus in Zeiten der Lüge und unterstützen Sie das Nachrichtenmagazin COMPACT mit einem  Abonnement der monatlichen Heftausgabe!
_von Katja Wolters
Die Menschheit solle die Kontrolle über sogenannte Killerroboter, waffenfähige Systeme, die ihre Ziele autonom identifizieren und angreifen können, unbedingt behalten, warnt ein Bericht der Menschenrechtsorganisation Human Rights Watch (HRW) und der Harvard Law School im Vorfeld der am Montag beginnenden UNO-Konvention Certain Conventional Weapons (CCW) in Genf.
„Das Mandat menschlicher Kontrolle schützt grundlegende moralische Prinzipien bei der Entscheidung über die Anwendung von Gewalt“, so HRW.
Dass Menschen ihre Kontrolle abtreten und „Entscheidungen über Leben und Tod“ Maschinen anvertrauten, sei eine reale Bedrohung.
Investierende Länder bräuchten klare Gesetzgebungen, „bevor die Technologie zu weit voranschreitet“.
Im April 2013 gründeten verschiedene Nichtregierungsorganisationen die Campaign to Stop Killer Robots (deutsch: Kampagne zur Aufhaltung der Killerroboter).
Im Juli 2015 unterzeichneten mehr als 1.000 Experten einen offenen Brief , in dem vor einem militärischen Wettrüsten künstlicher Intelligenz gewarnt wird.
„Die KI-Technologie hat einen Punkt erreicht, an dem der Einsatz [von autonomen Waffen]– praktisch, wenn auch nicht legal – innerhalb von Jahren plausibel ist, nicht Jahrzehnten“, glauben die Unterzeichner, darunter Astrophysiker Stephen Hawking und Apple Mitgründer Steve Wozniak.
„Der Einsatz ist hoch: autonome Waffen wurden als die dritte Revolution in der Kriegsführung beschrieben, nach dem Schießpulver und nuklearen Waffen.“
Im Januar dieses Jahres forderte der Vizevorsitzende der Vereinigten Stabschefs der USA, Gen. Paul Selva, eine nationale und globale Debatte über KI-Waffen für Luft- Land-, Meeres- und Unterwassergefechte.
„Wir sind tatsächlich in der Lage ‚selbstbestimmte‘ Gefährte in jeder dieser Kategorien zu konstruieren“, sagte Selva bei einer Veranstaltung des Brookings Instituts in Washington DC.
„Das bringt uns zu der entscheidenden Frage, ob wir willens sind oder nicht, über unbemannte autonome Systeme zu verfügen, die einen Feind angreifen können.
Was passiert, wenn solch ein durch künstliche Intelligenz betriebenes Gerät tödlichen Schaden anrichten kann?“
In seiner Budgetanfrage für das Jahr 2017 hat das US-Verteidigungsministerium zwischen 12 und 15 Milliarden US-Dollar für die Entwicklung künstlicher Intelligenz (KI) und lernfähiger Maschinen veranschlagt.
Weltweit rüsten Militärs hochtechnologisierter Länder in dieser Hinsicht auf.
Laut Selva existieren ethische, politische und kriegsrechtliche Fragen, die zu beantworten seien, bevor solche Waffen eingesetzt werden.
„Ich nenne es das Terminator-Rätsel“, sagte er.
„Meiner Ansicht nach muss diese Debatte national und international geführt werden.
Wollen wir als Menschen diese Linie überqueren?“
Apropos Terminator: Die Datenkrake NSA verfügt über ein Programm , mit dem in Pakistan die Metdadaten von 55 Millionen Handybesitzern ausgespäht werden.
Die zusammengetragenen Informationen werden von einem lernenden Algorithmus ausgewertet, der darüber entscheidet, ob jemand ein Terrorist ist oder nicht.
Der Name des Programms, das festlegt, ob diese Person Besuch von einer Killerdrohne bekommt oder nicht lautet SKYNET.
So heißt auch das künstliche Intelligenzsystem, dass in den Terminator-Filmen den Großteil der Menschheit vernichtet.
Fördern Sie ehrlichen Journalismus in Zeiten der Lüge und unterstützen Sie das Nachrichtenmagazin COMPACT mit einem  Abonnement der monatlichen Heftausgabe!
