Nimm das!
Wie Bots die Demokratie angreifen
Montage: der Freitag; Material: iStock, Fotolia
Saskia Esken ist eine fröhliche und schlagfertige Bundestagsabgeordnete.
Sie äußert ihre Meinung gern in 140 Zeichen .
Das ist die Zeichenzahl, die auf dem Kurzmitteilungsdienst Twitter das Maß aller Dinge ist.
Wer in dieser Kürze einen klaren, scharfen Satz formulieren kann, ist der Richtige für dieses Medium.
Dieser Artikel erschien in Ausgabe 04/2017 vom 26.01.2017 Die aktuelle Ausgabe des Freitag erhalten Sie am Kiosk.
Oder sichern Sie sich hier 3 Wochen gratis
Für die begeisterte Twitter-Nutzerin Esken war vor zwei Wochen allerdings Schluss mit lustig.
Sie hatte einen Tweet abgesetzt, in dem sie die Fluggesellschaft Air Berlin vor der US-amerikanischen Hetzplattform Breitbart warnte.
„@airberlin, Eure Werbung erscheint bei einer Neonazi-Website.
Das kann nicht gewollt sein, oder?“ , schrieb Esken.
Daraufhin brach eine Lawine über sie herein.
Die Parlamentarierin musste sich als „widerliche Denunziantin“, als „behindert“ und „Linksfaschistin“ beschimpfen lassen.
Der Strom wollte nicht mehr abreißen.
Eingebetteter Medieninhalt
Esken sieht sich als Vorreiterin des Digitalen.
Jede Form von Sperre oder Löschfunktion lehnt die Informatikerin ab – eigentlich.
Diesmal aber wurde es ihr zu viel.
„Ich habe etwas gemacht, was ich noch nie getan habe: Ich habe rund 50 besonders destruktive Twitter-Profile blockiert, damit ich mit den konstruktiven Kommentatoren im Dialog bleiben kann.“ Nur nutzte ihr das nichts.
Es waren einfach zu viele.
Sie fühlte sich „wie bei einer Schwarmattacke auf meinen Twitteraccount“.
Und sie ist nicht die einzige Abgeordnete, die betroffen ist.
Shitstorms sind kein neues Phänomen, Twitter begleiten sie eigentlich seit der Gründung des sozialen Netzwerks 2006.
In den vergangenen Monaten kam aber etwas Neues hinzu: Digitale Schlammwellen und die virale Kraft von Hassbotschaften werden zunehmend gezielt eingesetzt, um politische Gegner plattzumachen und den Austausch von Argumenten zu sabotieren.
Im September wird ein neuer Bundestag gewählt.
Was bedeutet es, wenn Kandidaten im Wahljahr mit Häme und Beschimpfungen außer Kraft gesetzt werden können?
Gefährden Meinungsroboter und Falschmeldungen eine faire Wahl?
Das sind derzeit häufig gestellte Fragen im Berliner Parlamentsviertel.
Der Bundestag zerbricht sich in dieser Woche in seinem Ausschuss für Technikfolgenabschätzung darüber den Kopf.
Alle Experten, die dort auftreten, sind sich einig: Ja, so genannte Social Bots und manipulierte Nachrichten wird es im Wahljahr verstärkt geben.
Der Fall Saskia Esken
Die SPD-Abgeordnete kritisierte, dass Air Berlin Anzeigen bei Breitbart schaltet.
Daraufhin setzte die Airline auch die Junge Freiheit auf eine schwarze Liste – ein Shitstorm begann.
Und alle Akteure betreten Neuland.
Bisher durchschaut nämlich keiner, wie Algorithmen die politische Kommunikation genau beeinflussen.
Nach Obamas erstem Wahlkampf 2008 galten die sozialen Medien noch als demokratische Verheißung, weil sie den Kreis aktiver, zivilisierter Teilnehmer an der Politik vergrößerten.
Es sei eine neue politische Agora entstanden, hieß es.
Ein virtueller Marktplatz, auf dem alle Bürger frei und gleich miteinander diskutierten könnten.
Ein Traum der Aufklärung, verwirklicht im Digitalen.
Anfang 2017 ist von diesen Hoffnungen nicht mehr viel übrig.
Pegida, AfD und rechte Wutbürger haben die sozialen Medien als Ort entdeckt, an dem sie sich organisieren – und hetzen.
Es scheint, als hätte ein Schwarm Enttäuschter und Verbitterter den Stammtisch mit Twitter und Facebook vertauscht.
Keiner muss mehr bei Zeitungen betteln, dass ein Leserbrief gedruckt wird.
Jeder ist heute sein eigener Publizist.
Aber die Shitstorms, die sich im Netz gegen Politiker entladen, sind nicht mehr nur handgemacht.
Ein geheimnisvoller Mechanismus vergrößert die Häme zu tsunamiartigen Fluten.
Die Formation der Herde
„Es war das Schlimmste, was ich in meiner politischen Laufbahn erlebt habe“, sagt Simone Peter, die Vorsitzende von Bündnis 90/Die Grünen.
Peter hat als Frau und Mitglied einer Moralpartei schon vieles an Häme einstecken müssen, jetzt aber kam es knüppeldick.
Binnen wenigen Stunden prasselte es auf die 51-Jährige herein.
„Da war alles dabei, was einen in der Seele verletzen kann“, sagt Peter.
„Üble rassistische Ausfälle, aber auch detaillierte Mordszenarien und Vergewaltigungsfantasien wurden mir geschickt.“
Auslöser waren Peters Kritik via Zeitung und Twitter, dass die Kölner Polizei mit dem Begriff #Nafri für „Nordafrikanische Intensivtäter“ in der Silvesternacht so genanntes racial profiling verfolgt habe.
Peter entschuldigte sich später bei der Polizei.
Aber das half ihr wenig.
Der Fall Simone Peter
Die Grünen-Vorsitzende lehnte den Begri #Nafri ab.
Dafür wurde sie von der Bild beleidigt und in den sozialen Medien gestalkt – mit maschineller Verstärkung durch Social Bots.
Der Aufakt für den Wahlkampf 2017?
Eine regelrechte Hatz begann.
Tausende Tweets und hässliche Kommentare bei Facebook fliegen der Parteichefin seit dem 2. Januar um die Ohren.
Wer die jüngsten Digitalattacken gegen Peter und Esken genauer betrachtet, dem fallen einige Details auf, die einen Verdacht nahelegen: Die Herde trampelte nicht spontan auf ihnen herum, sie folgte einer Formation.
Immer wieder befeuert wurde die Meute von rechten Twitter-Meinungsführern wie Dushan Wegner oder Felix Krautkrämer.
Der Buch-Autor und der Junge-Freiheit-Redakteur haben hohe Twitter-Followerzahlen, um die 10.000.
Wenn sie einen Tweet Richtung Abgeordnete abschießen, dann kopieren und verbreiten ihre Follower das in großer Zahl weiter.
„Retweeten“ nennt man das.
Der Tweet kommt dann nicht nur einmal an, sondern hundertfach.
Das ist die Schwarm-Logik sozialer Medien: Tweets multiplizieren sich und sorgen dafür, dass eine Welle entsteht.
Und mit dieser wird auch gezielt gedroht.
Felix Krautkrämer twitterte: „Wenn SPD-Politiker das Internet als Petz-Portal missbrauchen – Shitstorm“.
Zugleich mischen sich Twitter-Profile ein, die automatisiert auf bestimmte Themen reagieren – und wie eine digitale Schmutzkanone wirken.
Sie springen bei Stichworten wie #Nafri an oder sind auf politische Gegner abgerichtet.
Diese Social Bots oder „sozialen Roboter“ sind so programmiert, dass sie wie menschliche Nutzer wirken.
Sie folgen bestimmten Profilen, um automatisiert oder auf Befehl massenhaft Tweets auszusenden.
Viele mehr, als ein menschlicher Troll abschicken könnte.
Bots sind nicht per se schlecht, sie sind zunächst ein ganz selbstverständliches Werkzeug digitaler Kommunikation.
So werden sie zum Beispiel Jugendlichen auf Messenger-Apps angeboten, damit sie ihre vielen Nachrichten besser beantworten können.
Die blonde Anna führte jahrelang als Chat-Bot Kunden durch den Ikea-Katalog.
Ihr erster berühmter Vorläufer war „ Robert T-Online “, ein per Computeranimation verfremdeter echter Schauspieler.
Bei den heutigen Bots ist es anders.
Sie sehen nicht aus wie Menschen, sondern sie adaptieren ihre Fähigkeiten.
Grundlage ist ein digitales Sprachprogramm, das eine einfache Kommunikation führen kann.
Guter Bot, böser Bot
Bei Medienhäusern und in der Politik helfen Bots dabei, Hass-Kommentare auf Webseiten automatisch abzuweisen, wenn sie bestimmte Stichworte enthalten.
Die Grünen etwa testen gerade ein solches Programm.
„Gerade bei großen Shitstorm-Wellen ist es enorm aufwendig, die Kommentare von Hand zu moderieren“, sagt Robert Heinrich, der Wahlkampfmanager der Grünen.
Er habe sogar daran gedacht, eine Kunstfigur programmieren zu lassen, die das grüne Wahlprogramm erklärt.
Setzen die Grünen auch Social Bots bei Twitter ein, um die eigenen Botschaften zu verstärken?
„Nein“, sagt Heinrich, „und wir erwarten das auch von allen anderen Parteien.“ Auch die SPD erklärt, dass sie keine Bots hat.
Zehn echte Social-Media-Redakteure nähmen das Sortieren der Kommentare vor.
Ähnlich klingen die anderen Parteien: Böse Bots setzen wir nicht ein, aber gute Sortier- oder Chat-Bots sind denkbar.
„Wir wollen ja über unsere Webseite mit dem Bürger im Gespräch bleiben – eine wichtige Aufgabe der Parteien“, sagt FDP-Sprecher Nils Droste.
In einem CSU-geführten Ministerium heißt es: „Bots?
Ich bin froh, wenn ich mit meinem Outlook zurechtkomme.“
Andree Thieltges wiegt den Kopf, wenn er den Satz „Wir nutzen nur gute Bots“ hört.
„Das würde ich auch sagen, wenn ich als Politiker danach gefragt würde“, sagt der Sozialwissenschaftler, der sich Social-Media-Forensiker nennt.
Er will ein Verfahren entwickeln, um Social Bots erkennbar zu machen.
Indizien, dass sie im Einsatz sind, gibt es viele.
Die Twitter-Profile deutscher Politiker sind voller Fake-Profile.
Bis zu 60 Prozent der Follower seien nicht echt, fand das Online-Magazin Motherboard heraus.
Es seien Masken, hinter denen keine echten Menschen stehen.
An der Spitze: der große alte Mann des Bundestags, Hans-Christian Ströbele von den Grünen, der 59 Prozent Fake-Follower haben soll.
CDU-Generalsekretär Peter Tauber liege mit knapp 57 Prozent nur knapp dahinter.
Fake-Adressen unter den Followern von Politikern können verschiedene Funktionen haben.
Zunächst machen sie aus Politikern Scheinriesen bei Twitter.
Ohne Cyber-Prothese würde zum Beispiel Peter Taubers 111.000-Follower-Power auf 50.000 zusammenschrumpfen.
Die Accounts könnten befreundete Bots sein, welche die Reichweite der Politiker erhöhen, indem sie deren Tweets retweeten.
Die Profile könnten aber auch Schläfer sein, die erst aktiv werden, wenn jemand den Politiker auf dem Sozialen-Medien-Kanal unter Druck setzen will.
Studien haben gezeigt, dass der Einfluss von Bots auf die US-Präsidentenwahl massiv war.
Ein Drittel derjenigen, die Tweets von Donald Trump vervielfältigten, waren Automaten.
Trumps Bot-Armee war viermal so groß wie die Hillary Clintons.
Bot or not?
Ob hinter einem Twitter- Profil ein Mensch oder ein Social Bot steckt, lässt sich messen.
Je höher der Wert des Bot-Meters (siehe Bild), desto wahrscheinlicher steuert ein Programm den Twitter-Account.
Es werden dafür unter anderem die Kriterien Inhalt, Sendezeiten, Haltung des Users geprüft.
Mehrere Profile, die Simone Peter attackierten, erfüllten die Bot-Kriterien.
Die politische Wirkung der Tweets von Donald Trump ist enorm.
Dafür sind aber nicht nur die Hunderttausende von Retweets verantwortlich, sondern auch die klassischen Medien, weil Zeitungen und TV-Sender die 140-Zeichen-Botschaften aufgreifen.
„Trumps Tweets sind so effektiv, weil sie eine kurze, pointierte und autorisierte Botschaft sind, die Zeitungen sofort in Schlagzeilen umwandeln können“, sagt Jürgen Pfeffer, Professor für Computational Social Science an der TU München.
Die Kurznachrichten bekommen so eine teils enorme Wirkung.
Beispiel Jobs: Trump setzte kurz vor seiner Amtseinführung eine Reihe von Tweets ab, in denen er behauptete, dass ihm große Unternehmen wie Walmart, General Motors oder Bayer mehr Arbeitsplätze in den USA versprochen hätten.
Das war nur zum Teil PR: Ford etwa hat entschieden, ein in Mexiko geplantes Werk nicht zu bauen und stattdessen eines in den USA zu erweitern.
Ob die Jobs am Ende wirklich zurückkommen, wird sich erst später zeigen.
Kurzfristig erzeugte Trump aber den Eindruck, sein Versprechen zu erfüllen.
Gerade die Kombination alter und neuer Medien erzeugt so auf eine ganz neue Art Stimmungen.
Der Einfluss sozialer Medien in den USA und Deutschland ist nur eingeschränkt vergleichbar.
Die Twitter- und Facebook-Quoten in der Bevölkerung sind hierzulande kleiner.
Auch die Wechselwirkung zwischen sozialen und redaktionellen Medien ist nicht so ausgeprägt – noch.
Aber immer dann, wenn es das Zusammenspiel gibt, entwickelt die verdoppelte Meinung im öffentlichen Leben ihre Wucht.
Beispiel Simone Peter: Die Kritik an ihr begann nach Köln in den sozialen Medien, von da schwappte die Häme in die Bild-Zeitung.
Sie übernahm den Inhalt – und auch den rüden Ton der sozialen Medien.
Das Blatt nannte Peter „dumm, dümmer, GrüfrI“.
Das sollte „Grüne fundamentalistisch-realitätsfremde Intensivschwätzerin“ bedeuten.
In den sozialen Netzen fachte das den Sturm neu an.
Was am Ende herauskam, war eine beispiellose hybride Attacke aus sozialen und redaktionellen Medien auf eine deutsche Parteivorsitzende.
Schmähkritik lieferte Bild schon oft.
Hier aber war eine neue Qualität erreicht.
Denn unter den Angreifern war eine Reihe von Profilen, die die Analyse-Seite „Bot or Not“ als Social Bots identifiziert.
Sie weisen die typischen Eigenarten von Social Bots auf.
Twitter-Accounts ohne oder mit extrem vielen Followern; Adressen mit artifiziellen Namen oder aus dem Ausland; Profile, die vor allem mit anderen Bots kommunizieren oder Bot-Inhalte weiterverbreiten.
Die Grünen erlebten so wahrscheinlich eine der ersten orchestrierten Attacken, bei denen Maschinen die Wucht von Anführern und Trollen verstärkten.
Der politikverzerrende Effekt war ein dreifacher: Erstens wurde Simone Peter als Person herabgewürdigt.
Zweitens wurde ihre ablehnende Haltung zum Begriff „Nafri“ in der politischen Diskussion praktisch eliminiert.
Vor Köln gehörte es zum polizeilichen und journalistischen Kodex, dass auf Herkunftsmerkmalen fußende Fahndungskriterien zu vermeiden sind, weil sie stigmatisieren.
Dieser Konsens wurde durch die Schwarmattacke zerstört.
Der dritte Effekt ist vielleicht der einschneidendste.
Der Angriff richtete sich auf eine strategische Stelle im Parteiensystem.
Die Grünen befinden sich auf der politischen Landkarte zwischen den Blöcken der Konservativen und der Linken, mit Überlappungen in beide Lager hinein.
Das heißt, sie werden bei der Regierungsbildung im Herbst das Zünglein an der Waage sein.
Die Vorsitzende dieser Partei an die Wand drücken zu können, hat zum Auftakt des Wahljahrs ein starkes Zeichen gesetzt.
Die Grünen rutschten in den Umfragen prompt auf ihren schlechtesten Wert seit der letzten Bundestagswahl ab – 8,5 Prozent.
Wenn sie aber unter zehn Prozent fallen, ist keine schwarz-grüne und schon gar keine rot-rot-grüne Alternative zur ungeliebten Großen Koalition möglich.
Von dieser Konstellation würde vor allem eine Partei profitieren – die AfD.
Viele Profile der AfD mischten bei der Aktion „Grüne-unter-10-Prozent-beleidigen“ mit.
Die AfD war es auch, die den Einsatz von Social Bots zunächst begrüßt hatte.
„Selbstverständlich werden wir Social Bots in unsere Strategie im Bundestagswahlkampf einbeziehen“, sagte die AfD-Führungskraft Alice Weidel.
Zwei Tage später schränkte sie ein, Social Bots würden nicht „auf Seiten Dritter im Namen der AfD automatisiert posten oder Ähnliches“.
Die Angriffe gegen Peter waren nicht nur „im Namen“ der AfD, sie kamen aber ganz überwiegend aus ihrem politischen Spektrum.
Die beiden Fälle Peter und Esken zum Auftakt des Wahljahrs waren womöglich das Vorspiel für einen Hitech-Wahlkampf.
Inzwischen gibt es auch smarte Social Bots, die von künstlicher Intelligenz gesteuert sind.
Ihre Fähigkeit besteht darin, aus menschlichem Sprechverhalten so zu lernen, dass sie eigenständige Gespräche mit ihrem Gegenüber führen können.
Die Gefahr von Bots für die Meinungsbildung liegt aber nicht in ihrer individuellen Intelligenz.
Ihr Effekt beruht auf der schieren Masse des politischen Betrugs.
„Bots manipulieren politische Trends im großen Stil“, schreibt der Münchner Professor für Political Data Science Simon Hegelich.
„Im schlimmsten Fall verleiten sie Politiker dazu, in ihren Statements oder sogar in ihrer Politik auf solche Trends einzugehen.“ Social Bots sind sehr günstig zu erwerben.
1.000 Stück kosten rund 50 US-Dollar, ein Steuerprogramm für diese Bots schlägt mit 500 US-Dollar zu Buche.
„Social Bots werden nicht mehr verschwinden“, resümiert Hegelich.
Forscher am University College in London haben gerade ein ganzes Bot-Netz mit 350.000 noch schlafenden Twitteraccounts entdeckt, das sich wie ein Trapez über die USA und Europa spannt.
Sie nennen es Star-Wars-Bot-Netz, weil sie nicht wissen, wem diese Armee gehorchen wird.
Bemühte Abwehrversuche
Gegenstrategien existieren bisher praktisch nicht.
Die Grünen forderten kürzlich, Bots per Gesetz anmeldepflichtig zu machen.
Experten schmunzeln da.
„Wenn ich als Bot irgendwo auf der Welt sitze und programmierte Lügen raushaue“, sagt ein Forscher, „was interessiert es mich da, ob ich für Deutschland vorher ein Anmeldeformular ausfüllen sollte?“
Die ersten Politiker fliehen inzwischen von Twitter.
CSU-Lautsprecher Markus Söder etwa, der durch ulkige private Tweets und Stänkereien gegen Mesut Özil Beschimpfungen auf sich zog, macht seit September Twitterpause.
Saskia Esken wirkt ein paar Tage nach dem Shitstorm einigermaßen erholt.
„Ich werde mein Twitterverhalten nicht ändern“, sagt sie trotzig in ihrem Bundestagsbüro.
Auf zwei Wegen will sie gegen Häme und Falschmeldungen angehen.
„Einerseits die Dinge inhaltlich widerlegen und andererseits den Fake News die Geschäftsgrundlage entziehen.“ Also schrieb Esken nicht nur den Tweet, der dazu führte, dass Breitbart und Junge Freiheit keine Werbeplätze von Air Berlin mehr bekommen.
Sie verfasste später einen Artikel, um der Hetze ein argumentatives Narrativ entgegenzusetzen.
Vielleicht beruhigte sie sich damit auch selbst, im Nachhinein.
Im Moment des Pöbelsturms hätte sie mit dem Text nichts ausrichten können.
Jürgen Pfeffer findet solche Abwehrversuche bemüht.
Er sagt: „Ich glaube, dass Faktenchecks für die breite Masse beinahe sinnlos sind.“ Pfeffer schließt auch die Initiative Schmalbart und die Rechercheplattform Correctiv in dieses Urteil ein.
Beide wollen Fake News auf ihren Wahrheitsgehalt prüfen, um den rationalen Diskurs und die Zivilgesellschaft zu stärken.
„Die Hauptzielgruppe für solche Dinge sind meines Erachtens die Medien“, sagt Pfeffer.
Viel mehr als eine Beruhigungspille für Bürgerliche, Journalisten und Politik dürften Faktenchecker nicht sein.
Sie sollen glauben, die Bundestagswahl 2017 werde schon nicht so schlimm.
Gegen die Meinungsstürme, die von einer enttäuschten Wählerschaft losgetreten und von Bots aufgeblasen werden, helfen Fakten indes nicht.
„Es ist doch nicht so, dass wir keine Fakten hätten“, sagt Pfeffer.
Die Krise reiche inzwischen viel weiter, es herrsche ein grundsätzlicher Vertrauensverlust.
„Sie können an jeder Ecke in der Stadt einen Faktenschutzmann aufstellen, die Leute werden trotzdem nicht glauben.
Weil viele inzwischen denken: Es ist eh alles gelogen.“ Ein Klima, in dem Gewitter der Lüge und Häme Normalität werden.
Auch der Medienwissenschaftler Stephan Weichert ist skeptisch.
Er beklagt den prekären Zustand des – wie er es nennt – gesamten „Informations-Öko-Systems“.
Was Weichert so kunstvoll umschreibt, ist freilich nichts anderes als der Kern der Demokratie: die freie Meinungsbildung.
Und dass sie einem „Strukturwandel der Öffentlichkeit“ unterliegen kann, ist nicht neu.
Jürgen Habermas hat so einst den Übergang von Monarchie zu parlamentarischer Demokratie charakterisiert.
Habermas wollte wissen, wie sich Sprechregeln und demokratische Verfahren ändern, wenn sich der Kreis der Teilnehmer am politischen Diskurs vergrößert – etwa in den neuen Berliner Salons im Preußen des 18. Jahrhunderts.
Dort galt der Imperativ der „behutsamen Sprache der Vernunft“.
Jeder konnte seine Meinung kundtun, aber bitte nacheinander.
Satirische oder zweideutige Einwürfe waren verpönt.
Ein neuer Strukturwandel
Nun findet wieder ein Strukturwandel der Öffentlichkeit statt, diesmal beim Übergang von einer analogen in eine großteils digitale Demokratie.
Der Diskursraum soziale Medien erweitert erneut den Kreis der Teilnehmer.
Aber noch gibt es keine breit akzeptierten Sprechregeln.
Die Kennzeichen der sozialen Medien sind vielmehr Nichtlinearität und Algorithmus, also: Durcheinander und maschinelle Verstärkung.
Dem Algorithmus ist es dabei völlig egal, ob der Disput höflich geführt wird oder eine Meldung falsch ist.
Und eine Regulation sozialer Medien in Form von Zensur, Pressekodex oder Redakteuren existiert bislang nicht.
Falschmeldungen gab es natürlich auch früher.
Ihr Prototyp war die Emser Depesche, ein Bulletin über das Ergebnis einer Unterredung König Wilhelms I. mit einem französischen Gesandten.
Bismarck verkürzte und verfälschte die Botschaft.
Der politische Sinn der Emser Depesche war es, Stimmungen anzuheizen und die Willensbildung zur maximal denkbaren Reaktion zu treiben – Krieg.
Die Emser Depesche ist so etwas wie die Mutter der Fake News.
Nur tritt sie heute nicht mehr als Solitär auf, sondern als exponentiell verstärkte Mega-Provokation.
Tausendfach multiplizieren Bots Falschmeldungen und Hate Speech.
Üblicherweise dürfen wenige Tage vor der Wahl keine Umfragen mehr verbreitet werden.
Am Wahltag sind Prognosen vor 18 Uhr nicht erlaubt.
Jeder akzeptiert das als demokratische Sicherungen einer fairen Wahl.
Diese Regeln wirken geradezu hilflos angesichts der Tatsache, dass man über soziale Netzwerke Nachrichten in riesiger Auflage verbreiten kann, die schlicht falsch sind.
Auch kurz vor der Wahl.
Niemand kann das verhindern, keiner könnte diese Fake News noch wirksam falsifizieren.
Das bedeutet, die Demokratie ist in ihrem Herzen verwundbar: der freien, unverzerrten Meinungsbildung.
Die Demokratie steht unter akuter Disruptionsgefahr.
Teilen:
