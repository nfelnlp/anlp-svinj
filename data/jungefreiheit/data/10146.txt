© JUNGE FREIHEIT Verlag GmbH & Co.
www.jungefreiheit.de 07/17 / 10. Februar 2017
Wer hat Angst vorm bφsen Bot?
Internet: Politiker und Fachleute debattieren όber die Bedeutung kόnstlicher Profile in sozialen Netzwerken / Angst vor Propaganda
Peter Mφller
Sie sind die ultimative Geheimwaffe in jedem Wahlkampf.
Mit ein paar Klicks lassen sie angeblich ausgeklόgelte Wahlkampfstrategien ins Leere laufen und schicken aussichtsreiche Kandidaten plφtzlich auf die Verliererstraίe.
Die Rede ist von sogenannten Social Bots.
Dabei handelt es sich um Computerprogramme, die in den sozialen Medien wie Twitter und Facebook automatisch massenhaft Beitrδge posten und dadurch Diskussionen und Stimmungen beeinflussen kφnnen.
Glaubt man den Gerόchten, die όber die Macht dieser Meinungsroboter kursieren, haben sie Donald Trump zum Prδsidenten gemacht, den Brexit verursacht  und im Herbst werden sie fόr einen Durchmarsch der AfD bei der Bundestagswahl sorgen.
Hinter den Social Bots stehen nach der verbreiteten Lesart wahlweise die Geheimdienste Ruίlands und Chinas oder zwielichtige Konzerne.
Das Problem bei der ganzen Geschichte: Die wenigste wissen, was Social Bot eigentlich sind  und niemand kann wirklich sagen, welchen Einfluί sie tatsδchlich haben.
Zudem ist es bislang δuίerst schwierig, Meinungsroboter όberhaupt als solche zu erkennen.
Nur eines scheint derzeit sicher: Die Debatte όber den Umgang mit diesen Internetprogrammen beeinfluίt bereits jetzt die Auseinandersetzung όber den Wahlkampf in Deutschland.
Selbst das Bundesamt fόr Sicherheit in der Informationstechnik (BSI) warnt, Social Bots kφnnten den Wahlkampf im Herbst beeinflussen (JF 47/16).
Schon werden daher die Rufe nach einem Verbot oder zumindest einer Kenntlichmachung von Bots lauter.
Social Bots mόssen gekennzeichnet werden, forderte die Spitzenkandidatin der Grόnen, Katrin Gφring-Eckardt, Ende Januar in der Rheinischen Post.
Sie kόndigte einen entsprechenden Gesetzesvorstoί im Bundestag noch vor der Wahl an.
Dann kφnnen die Bόrger klar erkennen, wenn ein Tweet oder ein Post von einem Roboter erzeugt wurde, begrόndete die Grόnen-Politikerin ihre Idee fόr ein Anti-Bio-Siegel fόr Tweets (Die Zeit).
Auswirkungen auf politische Willensbildung unbekannt
Eine Rolle bei diesem Vorstoί dόrften die Erfahrungen gespielt haben, die Grόnen-Chefin Simone Peter Anfang des Jahres mit den sozialen Netzwerken gemacht hatte.
Nachdem sie die Kφlner Polizei fόr die massenhafte Kontrolle von mutmaίlichen nordafrikanischen Intensivtδtern (Nafris) in der Neujahrsnacht kritisiert hatte, erntete sie auf Twitter einen regelrechten Shitstorm, also einen Sturm der Entrόstung im Internet.
Es war das Schlimmste, was ich in meiner politischen Laufbahn erlebt habe, gestand Peter kόrzlich der Wochenzeitung Der Freitag.
In Tausenden Tweets erntete Peter teilweise heftige Kritik fόr ihre Δuίerungen, fόr die sie sich schlieίlich entschuldigte.
Auch in diesem Fall bleibt allerdings unklar, welche Rolle Social Bots dabei tatsδchlich spielten.
Fachleute sind angesichts populistischer Forderungen nach einer gesetzlichen Regulierung skeptisch.
Bei einer Expertenanhφrung des Ausschusses Digitale Agenda des Bundestages zum Thema Social Bots und Fake News Ende Januar verwies Markus Reuter von Netzpolitik.org darauf, daί bislang keine aussagekrδftige Studien darόber vorlδgen, welche Wirkungen und Effekte diese neuen Internetphδnomene auf die politische Meinungs- und Willensbildung όberhaupt haben.
Gleichzeitig hδtten manche der bislang bereits vorgeschlagenen Maίnahmen weitreichende und schδdigende Auswirkungen auf die Grundrechte der Presse- und Meinungsfreiheit, warnte Reuter vor όbertriebenem Aktionismus.
Doch wie funktionieren Social Bots eigentlich?
Das Bόro fόr Technikfolgen-Abschδtzung beim Deutschen Bundestag, das die Parlamentarier wissenschaftlich berδt, hat in einem Thesenpapier versucht, eine Definition zu erarbeiten.
Demnach sind Social Bots Computerprogramme, die eine menschliche Identitδt vortδuschen und zu manipulativen Zwecken eingesetzt werden, indem sie wie Menschen im Internet kommunizieren.
Echte Menschen, die mit dem Social Bot kommunizieren, nehmen diese nicht als durch Algorithmen ausgelφste automatische Kommunikation, sondern als echte Internetteilnehmer wahr und sind sich der Manipulation nicht bewuίt. Das Problem: Die Urheber von Social Bots konnten bislang bis auf wenige Ausnahmen nicht identifiziert oder rόckverfolgt werden.
Wer Twitter regelmδίig nutzt, stφίt frόher oder spδter auf eine relativ simple Form dieser Programme.
Bei Hashtags zu Themen, die gerade trenden, also zu denen innerhalb kurzer Zeit viele Tweets abgesetzt werden, beispielsweise nach einem Terroranschlag, erscheinen nach einer gewissen Zeit Werbetweets, die inhaltlich nichts mit dem ursprόnglichen Thema  zu tun haben, die aber denselben Hashtag verwenden.
Diese automatisch erzeugten Tweets sind in der Regel nur lδstig, zeigen aber, wie Meinungsroboter funktionieren.
Ein Beispiel fόr ein wesentlich komplexeres Botnetzwerk beschreibt der Mόnchner Politikwissenschaftler Simon Hegelich in einer Studie der Konrad-Adenauer-Stiftung.
Demnach seien im Zusammenhang mit dem Ukrainekon-flikt bis zu 15.000 Twitter-Accounts aktiv, die im Durchschnitt 60.000 Meldungen pro Tag absetzen.
Die Inhalte der Meldungen sind auf die antizipierten Interessen junger Mδnner in der Ukraine ausgerichtet: Die Bots reden viel όber Fuίball, erzδhlen sexistische Witze und verbreiten Links zum illegalen Download aktueller amerikanischer Kinofilme.
Zwischendurch werden aber gezielt Propaganda-Nachrichten des Rechten Sektors  einer ultranationalistischen ukrainischen Vereinigung mit paramilitδrischem Ableger  verbreitet, erlδutert Hegelich.
Dadurch werde gezielt versucht, aktuelle Trends zu beeinflussen, eigene Inhalte an eine genau definierte Zielgruppe zu transportieren sowie Falschinformation zu verbreiten.
Auch wenn das Beispiel aus dem letztlich militδrisch ausgetragenen Ukrainekonflikt stammt, ist das Grundmuster theoretisch auf jede andere Kampagne, die das Beeinflussen der φffentlichen Meinung zum Ziel hat, όbertragbar  beispielsweise fόr eine Bundestagswahl.
Um welche Dimensionen es sich dabei handeln kφnnte, macht eine wissenschaftliche Analyse von Millionen Tweets deutlich, deren Inhalte mit der amerikanischen Prδsidentschaftswahl zusammenhingen.
Das Ergebnis: Fast zwanzig Prozent aller Tweets zur Wahl seien von Maschinen und nicht von Menschen verfaίt worden, berichtete das Fachmagazin Spektrum der Wissenschaft.
Viele Politiker haben        Fake-Profile im Gefolge 
Ein Nebenaspekt der Debatte um Social Bots sind die sogenannten Fake-Follower.
Schδtzungen gehen davon aus, daί mittlerweile bis zu zwanzig Prozent aller Nutzer bei Twitter von Computern generiert wurden.
Spezielle Dienstleister bieten realen Nutzern diese Fake-Accounts zum Kauf an, damit sie ihre Follower-Zahl und so ihre Relevanz erhφhen kφnnen.
Wer viele Follower hat, wird von den sozialen Netzwerken privilegiert behandelt und erreicht somit auch mehr echte Nutzerinnen und Nutzer, beschreibt Hegelich das Problem.
Auch deutsche Politiker verfόgen teilweise όber eine groίe Zahl von Fake-Followern.
Ob diese gekauft sind oder gezielt von Bot-Programmen auf die Politiker angesetzt wurden, bleibt unklar.
Fakt ist: Bei 60 Prozent der 15.000 neuesten Follower des Grόnen-Bundestagsabgeordneten Christian Strφbele gibt es laut der Plattform Motherboard Anzeichen dafόr, daί es sich bei den entsprechenden Twitter-Konten um Fake-Profile oder Bots handelt.
Auf Platz zwei folgt Strφbeles Parteifreundin Gφring-Eckardt mit 58 Prozent Roboter-Followern, den dritten Platz belegt CDU-Generalsekretδr Peter Tauber (56 Prozent).
Bereits im vergangenen Jahr haben sich die Parteien einschlieίlich der AfD grundsδtzlich darόber verstδndigt, im anstehenden Bundestagswahlkampf auf Social Bots zu verzichten.
Die Befόrchtung der Strategen der etablierten Parteien: Vor allem die in den sozialen Medien besonders aktive AfD kφnnte mit Hilfe von automatisierten Programmen ihre Stellung im Internet weiter stδrken.
Ein Hintertόrchen lassen sich die meisten Parteistrategen trotz der einheitlichen Abwehrfront dennoch offen: Immer wieder ist zu hφren, daί gute Social Bots, die etwa dazu dienen, Diskussionen zu moderieren, weiterhin genutzt werden sollen.
Doch vielleicht ist alles ja auch nur halb so schlimm: Wahlentscheidend werden Social Bots vermutlich nie sein.
Alle Studien sprechen dagegen, daί jemand seine politische άberzeugung δndert, nur weil er eine Nachricht in den sozialen Netzwerken sieht, ist der Politikwissenschaftler Hegelich όberzeugt.
Social Bots
Social Bots oder auch Social Networking Bots (von englisch Robot, also Roboter) sind Programme, die in sozialen Netzwerken wie Facebook oder (noch hδufiger) Twitter als (falsches) Nutzerkonto auftauchen  und dabei menschliche Verhaltensmuster simulieren, um wie eine echte Person zu wirken.
Dabei beruhen sie auf bestimmten Algorithmen.
So sollen andere Nutzer  meistens fόr Marketingzwecke  getδuscht werden.
Bots eignen sich dazu, eine scheinbare Masse zu erzeugen, die ein bestimmtes Thema in den sozialen Netzwerken dominiert, also Trends setzt.
Schon fόr 50 Dollar kann man im Internet 1.000 gefδlschte Twitter-Profile kaufen, rund  150 Dollar muί man fόr (δltere und dadurch glaubwόrdige) Facebook-Profile investieren.
Niedersachsens Justizministerin Antje Niewisch-Lennartz (Grόne) hat angekόndigt, noch vor der Bundestagswahl gesetzlich gegen automatisierte Meinungsmacher vorzugehen.
